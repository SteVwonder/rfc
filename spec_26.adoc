ifdef::env-github[:outfilesuffix: .adoc]

26/Job Specification Version 2
==============================

A domain specific language based on YAML is defined to express the resource
requirements and other attributes of one or more programs submitted to a Flux
instance for execution.  This RFC describes the version 2 of jobspec, which
represents a request to run exactly one program.  This version is a simplified
version of the canonical jobspec format described in
link:spec_14{outfilesuffix}[RFC 14].  This version is an extended
version of the V1 jobspec format described in
link:spec_25{outfilesuffix}[RFC25].


* Name: github.com/flux-framework/rfc/spec_26.adoc
* Editor: Stephen Herbein <herbein1@llnl.gov>
* State: raw

== Language

The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD",
"SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to
be interpreted as described in http://tools.ietf.org/html/rfc2119[RFC 2119].

== Related Standards

* link:spec_4{outfilesuffix}[4/Flux Resource Model]
* link:spec_8{outfilesuffix}[8/Flux Task and Program Execution Services]
* link:spec_14{outfilesuffix}[14/Canonical Job Specification]
* link:spec_20{outfilesuffix}[20/Resource Set Specification Version 1]
* link:spec_25{outfilesuffix}[25/Job Specification Version 1]

== Goals

TODO: should we restrict this to just Nodes, CPUs, and GPUs?

* Express the resource requirements of a program to the scheduler.
* Allow resource requirements to be expressed in terms of Nodes, CPUs, and GPUs.
* Support the forms of jobspec produced by the `flux run` command.
* Express program attributes such as arguments, run time, and
task layout, to be considered by the program execution service (RFC 12)

== Overview

This RFC describes the version 2 form of "jobspec", a domain specific language
based on YAML footnote:[http://yaml.org/spec/1.1/current.html[YAML Ain't Markup
Language (YAML) Version 1.1], O. Ben-Kiki, C. Evans, B. Ingerson, 2004.].  The
version 2 of jobspec SHALL consist of a single YAML document representing a
reusable request to run exactly one program.  Hereafter, "jobspec" refers to the
version 2 form, and "non-canonical jobspec" refers to the non-canonical form.

== Jobspec Language Definition

A jobspec V2 YAML document SHALL consist of a dictionary
defining the resources, tasks and other attributes of a single
program. The dictionary MUST contain the keys `resources`, `tasks`,
`attributes`, and `version`.

Each of the listed jobspec keys SHALL meet the form and requirements
listed in detail in the sections below. For reference, a ruleset for
compliant jobspec V2 is provided in the *Schema* section below.

=== Resources

The value of the `resources` key SHALL be a strict list which MUST define either
`node` or `slot` as the first and only resource. Each list element SHALL
represent a *resource vertex* (described below). These keys and definitions are
similar to those in Jobspec V1. V2 adds the `exclusive` key and uses the
canonical jobspec defintion for `count`, rather than the simplified definition
used in V1.

A resource vertex SHALL contain the following keys:

* type
* count
* unit
* with
* label
* exclusive

The definitions of `count`, `unit`, `with`, `label`, and `exclusive` SHALL match
those found in RFC14.  The others are redefined and simplified to mean the
following:

 *type*::
 The `type` key for a resource SHALL indicate the type of resource to be
 matched. In V2, only four resource types are valid: [`node`, `slot`, `core`,
 and `gpu`]. `slot` types are described in the *Reserved Resource Types* section
 below.

==== V2-Specific Resource Graph Restrictions

In V2, the `resources` list MUST contain exactly one element, which MUST be
either `node` or `slot`.  Additionally, the resource graph MUST contain the
`core` type.

In V2, there are also restrictions on which resources can have `out` edges to
other resources. Specifically, a `node` can have an out edge to a `slot` (and
vice-versa), and both a `node` and a `slot` can have an `out` edge to a `core`
(but not vice-versa).  If a `node` or `slot` has an `out` edge to a `core`, it
can also, optionally, have an `out` edge to a `gpu` as well. Therefore, the
complete enumeration of valid resource graphs in V2 is:

. `slot>core`
. `node>slot>core`
. `slot>node>core`
. `slot>(core,gpu)`
. `node>slot>(core,gpu)`
. `slot>node>(core,gpu)`

TODO: do we allow `node>slot`, `slot`, and/or `slot>node` ?

In V2, an `exclusive` key with a value of `false` SHALL NOT be included in a
`slot` or any of its children.

TODO; do we allow the above? Any value to adding exclusive support?

=== Tasks

The value of the `tasks` key SHALL be a strict list which MUST define exactly
one task. The list element SHALL be a dictionary representing a task to run as
part of the program. A task descriptor SHALL contain the following keys, whose
definitions SHALL match those provided in RFC14:

 * command
 * slot
 * count
 ** per_slot
 ** per_resource
 ** total
 * attributes
 * distribution

These keys are the same as those in Jobspec V1 except for the addition of
`per_resource`, which enables the late-binding of tasks to resources (i.e., the
number of tasks is determined after the resource request is allocated by the
scheduler).

TODO: do we want to restrict `per_resource` values to some list of resources
(maybe only those in the jobspec being validated/written)?

=== Attributes

The `attributes` key SHALL be a dictionary of
dictionaries.  The `attributes` dictionary MUST contain `system` key and MAY
contain the `user` key.  Common `system` keys are listed below, and their
definitions can be found in RFC14.  Values MAY have any valid YAML type.

 * user
 * system
 ** duration
 ** environment
 ** cwd

Most system attributes are optional, but the `duration` attribute is required in
jobspec V2.

These keys are the same as those in Jobspec V1.

TODO: do we also want to add job dependencies?

---

=== Example Jobspec

Under the description above, the following is an example of a fully compliant
version 2 jobspec. The example below declares a request for 4 "nodes"
each of which with 1 task slot consisting of 2 cores each, for a total
of 4 task slots. A single copy of the command `app` will be run on each
task slot for a total of 4 tasks.

[source,yaml]
----
include::data/spec_26/example1.yaml[]
----

== Basic Use Cases

To implement basic resource manager functionality, the following use
cases SHALL be supported by the jobspec:

=== Section 1: Node-level Requests

The following "node-level" requests are all requests to start an instance,
i.e. run a single copy of `flux start` per allocated node. Many of these
requests are similar to existing resource manager batch job submission or
allocation requests, i.e. equivalent to `oarsub`, `qsub`, and `salloc`.

'''
Use Case 1.1:: Request nodes outside of a slot
+
Specific Example:: Request 4 nodes, each with 1 slot
+
Existing Equivalents::
+
|===
| Slurm | `salloc -N4`
| PBS | `qsub -l nodes=4`
|===
+
Jobspec YAML::
+
[source,yaml]
----
include::data/spec_26/use_case_1.1.yaml[]
----
'''

Use Case 1.2:: Request nodes inside of a slot
+
Specific Example:: Request 4 slots, each with 1 node
+
Existing Equivalents::
+
|===
| Slurm | `salloc -N4`
| PBS | `qsub -l nodes=4`
|===
+
Jobspec YAML::
+
[source,yaml]
----
include::data/spec_26/use_case_1.2.yaml[]
----
'''

Use Case 1.3:: Request a fixed number of cores with no constraint on nodes
+
Specific Example:: Request 120 cores, one broker per node
+
Existing Equivalents::
+
|===
| TODO
|===
+
Jobspec YAML::
+
[source,yaml]
----
include::data/spec_26/use_case_1.3.yaml[]
----
'''

=== Section 2: General Requests

The following use cases are more general and include more complex slot placement
and task counts.

'''
Use Case 2.1:: Run N tasks across M nodes
+
Specific Example:: Run `hostname` 20 times on 4 nodes, 5 per node
+
Existing Equivalents::
+
|===
| Slurm | `srun -N4 -n20 hostname` or `srun -N4 --ntasks-per-node=5 hostname`
| PBS   | `qsub -l nodes=4,mppnppn=5`
|===
+
Jobspec YAML::
+
[source,yaml]
----
include::data/spec_26/use_case_2.1.yaml[]
----

'''
Use Case 2.2:: Run N tasks across M nodes, unequal distribution
+
Specific Example:: Run 5 copies of `hostname` across 4 nodes,
default distribution
+
Existing Equivalents::
+
|===
| Slurm | `srun -n5 -N4 hostname`
|===
+
Jobspec YAML::
+
[source,yaml]
----
include::data/spec_26/use_case_2.2.yaml[]
----

'''
Use Case 2.3:: Run N tasks, Require M cores per task
+
Specific Example:: Run 10 copies of `myapp`, require 2 cores per copy,
for a total of 20 cores
+
Existing Equivalents::
+
|===
| Slurm | `srun -n10 -c 2 myapp`
|===
+
Jobspec YAML::
+
[source,yaml]
----
include::data/spec_26/use_case_2.3.yaml[]
----

=== Schema

A jobspec conforming to version 2 of the language definition SHALL
adhere to the following ruleset, described using JSON Schema
footnote:[https://json-schema.org/latest/json-schema-core.html[JSON Schema: A Media Type for Describing JSON Documents]; H. Andrews; 2018].

[source,json]
----
include::data/spec_26/schema.json[]
----

